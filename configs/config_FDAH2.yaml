inputdir: /fast/projects/damm_establish_ht_xs/scratch/191115_A00643_0025_BHHGH2DRXX/  # source of fastq files (subfolders allowed)
workdir: /fast/users/szyskam_c/scratch/projects/FDAH2 # here your results are created
snakedir: /fast/users/szyskam_c/snakes/projects/somVarWES
samples: # here go all your samples
  samplesheet: /fast/users/szyskam_c/snakes/projects/somVarWES/configs/FDAH2_sheet.csv
  tumor:
    - A  # 
  normal:
    - B  # if more than one, the first normal will be used as default for tumor-sample
  reads:
    - R1
    - R2
  separation: '_'
setup:  
  run: PE
  phred: 33
  readlength: 150  # neccessary???
  library: SureSelect  # have to be found at bed_files/SureSelect/<build>/SS_<library_version>_<build>_<Padded | Covered>[_nochr].bed
  library_version: HAEv7
  UMI: index  #suffix of the fastq file containing the UMI-barcode information 

#### ABSOLUTE PATHS ############
paths:
  mystatic: /fast/groups/ag_damm/work/ref/
  bihstatic: /fast/projects/cubit/current/static_data
  scripts: scripts/ # folder relative to snakedir
#### REF SECTION ###############
ref:
  build: hg38
  hg19:
    genome_path: genome/gatk/b37
    genome: genome/gatk/b37/human_g1k_v37.fasta
    candidates: /fast/users/szyskam_c/work/utils/bulltools/known_sites/candidate_genes_aml.txt
    dbsnp: annotation/gatk/b37/dbsnp_138.b37.vcf
    dbsnp_all: annotation/gatk/b37/All_20180423.vcf
    dbsnp_common: annotation/gatk/b37/common_all_20180423.vcf
    gold_standard_indels: annotation/gatk/b37/Mills_and_1000G_gold_standard.indels.b37.vcf
    phase1k_indels: annotation/gatk/b37/1000G_phase1.indels.b37.vcf
    # bed_file: bed_files/SureSelect/hg19/SS_HAEv6r2_hg19_Covered_nochr.bed
    # bed_file_pad: bed_files/SureSelect/hg19/SS_HAEv6r2_hg19_Padded_nochr.bed
  hg38:
    genome_path: genome/gatk/hg38/
    genome: genome/gatk/hg38/hg38.fasta
    dbsnp: annotation/gatk/hg38/dbsnp_138.hg38.vcf
    dbsnp_all: annotation/gatk/hg38/All_20180418.vcf
    dbsnp_common: annotation/gatk/hg38/common_all_20180418.vcf
    gold_standard_indels: annotation/gatk/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf
    phase1k_indels: annotation/gatk/hg38/1000G_phase1.snps.high_confidence.hg38.vcf # seems to work instead of indels (acc. to GATK blog: https://gatkforums.broadinstitute.org/gatk/discussion/6800/known-sites-for-indel-realignment-and-bqsr-in-hg38-bundle)
    # bed_file: bed_files/SureSelect/hg38/SS_HAEv7_hg38_Covered.bed
    # bed_file_pad: bed_files/SureSelect/hg38/SS_HAEv7_hg38_Padded.bed
#### TOOLS SECTION ##############
tools:
  gatk: gatk # 
  gatk3: java -jar /fast/users/szyskam_c/work/utils/gatk3.8/GenomeAnalysisTK.jar -T
  annovar: perl /fast/users/szyskam_c/tools/annovar2018
  # annovar: perl /fast/users/szyskam_c/tools/annovar2019
scripts:
  split_fastq: shell/split_fastq.mawk
  prettifyBED : shell/prettify_BEDcoverage.awk
  anno_format: shell/anno_format.mawk
  vcf2table: shell/vcf2table.mawk
  cleanpileup: shell/cleanpileup.mawk
  varscan2table: shell/varscan2table.mawk
  anno_info: shell/anno_info.mawk
  csv2bed: shell/csv2bed.mawk
  pon2cols: shell/pon2cols.mawk
  format_bed_coverage: shell/formatCoverage.sh
  cleanpileup: shell/cleanpileup.mawk
  pile2count: shell/pile2count.mawk
  matrix2EBinput: shell/matrix2EBinput.mawk
  makeponlist: shell/makeponlist.sh

  # merge_anno: merge_anno.py
  # expand_info: shell/expand_info.sh
  
  # filter_csv: shell/filter_exome_wFlankingSeq.sh
fastq:
  threads: 4
  subsample_normal_factor: 1  # for testing purpose
  split_factor: 20 # split fastqs and run pipeline on split files --> merge before deduplication
qc:
  samplefactor: 1
trim:
  program: trimmomatic
  trimming: True
  threads: 24
  adapters: configs/SureSelectXT.fa
  mode: 
    - "AVGQUAL:20"
    - "SLIDINGWINDOW:4:15"
    - "LEADING:3"
    - "ILLUMINACLIP:<adapter>:2:30:10"
  suffix:
    - "trim"  # suffix for paired output
    - "trim_UP" # suffix for unpaired output
alignment:
  tool: bwa
  threads: 16
bamindex:
  threads: 2
tag_bam: # needs enough RAM for loading entire uncompressed index fastq into memory
  run: True
  max_mem: 30g # memory for java VM (30g seems neccessary - needs to be smaller than threads * vmem/thread)
resplit_bam:
  threads: 4
dedup:
  threads: 4
dedup_umi:
  max_mem: 10g
  keep_dups: True # keep dups if you want to perform UMI-correction
realignGATK:
  threads: 16
recalib:
  run: True
  threads: 12
  known_sites: dbsnp_common   # which dbsnp database to use beside gold_standard_indels and phase1k
cover_bed:
  histo_steps: "0 1 10 15 50 100 120 200 500 1000 1500 2000 2500"
mpileup:
  Q: 25   # base quality
  MAPQ: 20 # -q in pileup
varscan:
  threads: 8
  vcf: True # VCF output is necessary for left-alignment
  min-coverage: 1
  min-var-freq: 0.01
  min-freq-for-hom: 0.75
  normal-purity: 0.95
  tumor-purity: 0.8
  p-value: 0.99
  somatic-p-value: 0.05
annovar:
  threads: 10
  path_to_humandb: annotation/annovar/humandb
  annofiles:
    - refGene
    - cytoBand
    - genomicSuperDups
    # - esp6500_all
    - esp6500siv2_all  #
    # - 1000g2010nov_all
    - 1000g2014oct_all
    - gnomad_exome_all
    # - gnomad_af.lna # not indexed
    # - exac03_all
    # - dbscsnv11
    # - snp131
    # - snp131NonFlagged
    - snp138
    - snp138NonFlagged
    - avsnp138
    - avsnp150
    - cosmic70
    - cosmic90
    # - clinvar_20150629
    # - clinvar_20170905
    - clinvar2019_short
    # - ljb26_all
    # - dbnsfp30a
    - dbnsfp35a
    - spidex
    - icgc29
Fisher_strand:
  threads: 20
EBFilter:
  run: True
  pon_list: PoN/HAEv7_hg38_NovaSeq/Pon_list.txt # path relative to mystatic path
  use_cache: False
  cache_folder: PoN/HAEv7_hg38_NovaSeq_q20 # path relative to mystatic path
  threads: 
    makeEBcache: 20
    EBscore: 20
    EBsplit_factor: 20 # into how many jobs is makeEBcache divided per chromosome
  params:
    sep: tab
    MAPQ: 20   # I guess this should be lower than the mapping quality used for mpileup or not?
    Q: 25
    fitting_penalty: 0.5
filter:
  threads: 2
  filters:
    bull:  # changed from -name: bull  # this is also the extension used in the filtered output (_bull.csv)
      run: False
      path: bullinger.py # filters are expected in scripts/filters
      params: 
        TM2_limit: 4
    damm:
      run: True
      path: damm.py
      params:
        TM2_limit: 4
        candidate_list: annotation/damm_lists/AML_candidates.txt
        driver_list: annotation/damm_lists/AML_drivers.txt
        keep_syn: True
filter_bam:
    threads: 4