# ################# FILTER ###################################################
rule filter_variants:
    input: "table/{sample}_{tumor}-{norm}.raw.csv"
    output: "filter/{sample}_{tumor}-{norm}.{filter}.csv"
    wildcard_constraints:
        sample = "[^_]+"
    conda:
        "../env/filter-env.yml"
    threads:
        config['filter']['threads']
    script:
        "../scripts/filter.py"


def reduce_regions(df, padding):
    '''
    takes a mutation list and returns a region list using padding
    overlapping regions are reduced to one using the gap strategy
    '''

    df = df.sort_values('Start')
    df['Start'] = df['Start'] - padding
    df['End'] = df['End'] + padding
    # find the break points
    # if Start is greater than previous End (using shift), this is a gap --> df['gap'] = 1
    df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')
    # id different reads according to gap
    # cumulative sum does not increase at df['gap'] == 0 and so these consecutive stretches are grouped together
    df['gap'] = df['gap'].cumsum()
    # groupby the coverage break group and condense individual coverage islands
    # agg has to contain the neccessary shared columns TransLength because it is needed for coverage computation
    new_df = df.groupby('gap').agg({'Start': 'min', 'End':'max'})
    new_df = new_df
    return new_df.reset_index('gap').drop(columns='gap')


def mut2bed(mut_file, padding, bed_file):
    # read the anno_file
    anno = pd.read_csv(mut_file, sep='\t').sort_values(['Chr', 'Start']).iloc[:,:5]
    # get the bedfie with padded and collapsed regions
    bed = anno.groupby('Chr').apply(reduce_regions, padding)
    # remove Chr index
    bed = bed.reset_index().drop(columns='level_1')
    bed.to_csv(bed_file, index=False, sep='\t', header=False)
    return bed_file


def get_bed_file(w, input):
    '''
    serves as a params function creating and returning the bed file for the samtools view
    '''
    padding = config['filter_bam']['padding']
    bed_file = mut2bed(input[0], padding, f"filter_bam/{w.sample}_{w.type}.bed")
    return bed_file


# rule filter_bam:
#     input: 
#         "filter/{sample}_{tumor}-{norm}.{filter}.loose.csv",
#         "recalib/{sample}_{type}.bam",
#         "recalib/{sample}_{type}.bai"
#     output:
#         "filter_bam/{sample}_{type}.bam",
#         "filter_bam/{sample}_{type}.bai"
#     threads:
#         config['filter_bam']['threads']
#       params:
#            bed = get_bed_file
#     :

#
#
#
#
#
