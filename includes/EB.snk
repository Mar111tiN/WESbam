rule anno2EB:
    input:
        table = "table/{sample}_{tumor}-{norm}.{chrom}.csv",
        tumor_bam = "recalib/{sample}_{tumor}.{chrom}.bam",
        tumor_bai = "recalib/{sample}_{tumor}.{chrom}.bai"
    output:
        "eb/{sample}_{tumor}-{norm}-{chrom}.EB"
    log:
        "logs/eb/{sample}_{tumor}-{norm}-{chrom}.log"
    threads:
        config['EBFilter']['threads']['EBscore']
    conda:
        f"../{config['envs']}/eb-env.yml"
    params:
        cleanpileup = get_script('cleanpileup'),
        csv2bed = get_script('csv2bed'),
        pon2cols = get_script('pon2cols'),
        pile2count = get_script('pile2count'),
        matrix2EBinput = get_script('matrix2EBinput'),
        makeponlist = get_script('makeponlist')
        # refgen = full_path('genome')
    script:
        "../scripts/eb.py"
        # should I repileup the target with separate Q and q --> ask Kenyishi


def get_cache(w):
    '''
    retrieves path to chrom.cache from the wildcards.chrom
    '''

    chrom = w.chrom
    EBcache_path = static_path(config['EBFilter']['pon_list'])
    cache_folder = os.path.join(config['paths']['mystatic'], config['EBFilter']['cache_folder'])
    EBcache_folder = os.path.join(cache_folder, "EBcache")
    EB_cache_file = os.path.join(EBcache_folder, f"{chrom}.cache")
    return EB_cache_file


rule anno2EB_EBcache:
    input:
        table = "table/{sample}_{tumor}-{norm}.{chrom}.csv",
        tumor_bam = "recalib/{sample}_{tumor}.{chrom}.bam",
        tumor_bai = "recalib/{sample}_{tumor}.{chrom}.bai",
        EBcache = get_cache
    output:
        "eb/{sample}_{tumor}-{norm}-{chrom}.cachedEB"
    log:
        "logs/eb/{sample}_{tumor}-{norm}-{chrom}.log"
    threads:
        config['EBFilter']['threads']['EBscore']
    resources:
        # ebfromcache.py fails for some files with higher thread numbers during the process pooling
        # no idea why that is but gradually reducing the threads incrementally allows more files to run to completion
        # solution:
        # run snakemake with the --restart-times option and compute adjusted thread with the resources option, ..
        # that decreases depending on the attempts used
        threads_adjusted = lambda wildcards, threads, attempt: max(1, threads - (attempt - 1) * 6),
        attempts = lambda _, attempt: attempt
    conda:
        f"../{config['envs']}/eb-env.yml"
    params:
        cleanpileup = get_script('cleanpileup'),
        csv2bed = get_script('csv2bed'),
        pon2cols = get_script('pon2cols'),
        pile2count = get_script('pile2count'),
        matrix2EBinput = get_script('matrix2EBinput'),
        reducematrix = get_script('reducematrix'),
        reorder_matrix = get_script('reordermatrix')
        # refgen = full_path('genome')
    script:
        "../scripts/ebfromcache.py"


# ######################## MERGE ####################################################

def get_mergeEBscore_input(w):
    '''
    performs the input switch for mergeEBscore
    '''

    if config['EBFilter']['use_cache']:
        input_list = [f"eb/{w.sample}_{w.tumor}-{w.norm}-{chrom}.cachedEB" for chrom in chrom_list]
    else:
        input_list = [f"eb/{w.sample}_{w.tumor}-{w.norm}-{chrom}.EB" for chrom in chrom_list]
    val_list = []
    for _input in input_list:
        if os.path.isfile(_input):
            if os.path.getsize(_input) > 20:
                val_list.append(_input)
        else:
            continue
    return val_list


rule mergeEBscore:
    input:
        get_mergeEBscore_input
        # input switch for cached eb-files
    output:
        "table/{sample}_{tumor}-{norm}.EB.csv"
    threads:
        4
    run:
        anno_df = pd.read_csv(input[0], sep='\t', index_col=False)
        EB_dfs = []
        for EB_file in input:
            EB_df = pd.read_csv(EB_file, sep='\t', index_col=False)
            # cleanup after
            # shell(f"rm {EB_file}")
            if EB_df.empty:
                continue
            EB_dfs.append(EB_df)
        EB_merge = pd.concat(EB_dfs).sort_values(['Chr', 'Start'])

        # sort nicely
        cols = ['Chr', 'Start', 'End', 'Ref', 'Alt', 'EBscore', 'PoN-Ref', 'PoN-Alt']
        if config['EBFilter']['full_pon_output']:
            base_cols = list("AaGgCcTtIiDd")
            col_name = "|".join(base_cols)
            cols.append(col_name)
        EB_merge = EB_merge[cols]
        EB_merge.to_csv(output[0], sep='\t', index=False)
        show_output(f"Written EB-annotated file to {output[0]}", color='success')
