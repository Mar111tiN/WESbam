rule index_split_bam:
    input:
        "{folder}/{sample}_{type}.{chrom_split}.bam"
    output:
        "{folder}/{sample}_{type}.{chrom_split}.bai"
    threads:
        config['bamindex']['threads']
    conda:
        "../env/align-env.yml"
    shell:
        "picard BuildBamIndex INPUT={input}"

rule index_bam:
    input:
        "{folder}/{sample}_{type}.bam"
    output:
        "{folder}/{sample}_{type}.bai"
    threads:
        config['bamindex']['threads']
    conda:
        "../env/align-env.yml"
    shell:
        "picard BuildBamIndex INPUT={input}"

rule merge_bam:
    '''
    here the split and umified bams are merged
    depending on input required by recalib, this can be umi/X-Y.bam or mapped
    !!! the merge has to retain the bam headers of the individual files

    '''

    input:  # here I need a switch if no UMI is involved
        expand("mapped/{{sample}}_{{type}}.{split}.bam", split=list(range(config['fastq']['split_factor'])))
    output:
        "bam_merge/{sample}_{type}.bam"
    threads:
        config['resplit_bam']['threads']
    conda:
        "../env/samba-env.yml"
    shell:
        "sambamba merge -t {threads} {output} mapped/{wildcards.sample}_{wildcards.type}.*.bam; "
        # "rm {input};"

        # OPTIONB: picard AddOrReplaceReadGroups

rule resplit_bam:
    '''
    chromosome-split merged bams into chromosome-split bams (one split per job) with index
    '''

    input:
        "bam_merge/{sample}_{type}.bam",
        "bam_merge/{sample}_{type}.bai"
    output:
        "bam_merge/{sample}_{type}.{chrom}.bam"
    threads:
        config['resplit_bam']['threads']
    conda:
        "../env/samba-env.yml"
    shell:
        "sambamba view -n {threads} -h -o {output} {input} {wildcards.chrom}"


rule dedup:
    input:
        "bam_merge/{sample}_{type}.{chrom}.bam"
    output:
        "deduped/{sample}_{type}.{chrom}.bam"
    log:
        "logs/dedup/{sample}_{type}.{chrom}.log"
    params:
        metric = lambda w: f"deduped/{w.sample}_{w.type}.{w.chrom}.metric.txt"
    threads:
        config['dedup']['threads']
    conda:
        "../env/align-env.yml"
    shell:
        "picard MarkDuplicates I={input} O={output} M={params.metric} REMOVE_DUPLICATES=true &>{log}"


rule dedup_umi:
    input:
        "bam_merge/{sample}_{type}.{chrom}.bam"
    output:
        "umi_deduped/{sample}_{type}.{chrom}.bam"
    params:
        metric = lambda w: f"umi_deduped/{w.sample}_{w.type}.{w.chrom}.metric.txt",
        umi_metrics = lambda w: f"umi_deduped/{w.sample}_{w.type}.{w.chrom}.umi_metric.txt",
        max_mem = config['dedup_umi']['max_mem'],
        remove_dups = "false" if config['dedup_umi']['keep_dups'] else "true"
    threads:
        int(config['dedup_umi']['max_mem'].strip('g'))
    log:
        "logs/dedup/{sample}_{type}.{chrom}.log"
    conda:
        "../env/align-env.yml"
    shell:
        "picard UmiAwareMarkDuplicatesWithMateCigar -Xms500m -Xmx{params.max_mem} UMI_METRICS={params.umi_metrics} I={input} O={output[0]} M={params.metric} ASSUME_SORTED=true REMOVE_DUPLICATES={params.remove_dups}; " # &>{log}


def IR_ref(_):
    '''
    returns ref parameters for realign-refs gatk tools
    '''

    return f"-R {full_path('genome')} -known {full_path('gold_standard_indels')} -known {full_path('phase1k_indels')}"


rule create_GATK_target_list:
    input:
        unpack(get_IR_input)
    output:
        "realigned/{sample}_{type}.{chrom}.intervals"
    threads:
        config['realignGATK']['threads']
    log:
        "logs/realign/targetList"
    conda:
        "../env/gatk3-env.yml"
    params:
        gatk = config['tools']['gatk3'],
        ref = IR_ref
    shell:
        "{params.gatk} RealignerTargetCreator -nt {threads} {params.ref} -I {input.bam} -o {output} &>{log}"


rule realignGATK:
    input:
        unpack(get_IR_input),
        intervals = "realigned/{sample}_{type}.{chrom}.intervals"
    output:
        "realigned/{sample}_{type}.{chrom}.bam"
    log:
        "logs/realign/{sample}_{type}.{chrom}.log"
    threads:
        config['realignGATK']['threads']
    conda:
        "../env/gatk3-env.yml"
    params:
        gatk = config['tools']['gatk3'],
        ref = IR_ref
    shell:
        "{params.gatk} IndelRealigner {params.ref} "
        "-targetIntervals {input.intervals} -I {input.bam} -o {output} &>{log}"


rule base_recalibrator:
    input:
        bam = "realigned/{sample}_{type}.{chrom}.bam",
        bai = "realigned/{sample}_{type}.{chrom}.bai"
    output:
        bam = "recalib/{sample}_{type}.{chrom}.bam",
        table = "recalib/{sample}_{type}.{chrom}.recal_table"
    log:
        "logs/recalib/{sample}_{type}.{chrom}.log"
    params:
        gatk = config['tools']['gatk'],
        genome = f"-R {full_path('genome')}",
        known_sites = f"--known-sites {full_path('gold_standard_indels')} --known-sites {full_path('phase1k_indels')} --known-sites {full_path(config['recalib']['known_sites'])}",
        apply_table = lambda w, input, output: f"--bqsr-recal-file recalib/{w.sample}_{w.type}.recal_table -O {output}"
    threads:
        config['recalib']['threads']
    conda:
        "../env/gatk4-env.yml"
    shell:
        "{params.gatk} BaseRecalibrator -I {input.bam} {params.genome} {params.known_sites} -O {output.table} &>{log}; "
        # apply recalibration table on input
        "{params.gatk} ApplyBQSR -I {input.bam} {params.genome} --bqsr-recal-file {output.table} -O {output.bam} &>>{log}; " # 
        # recreate recalibration table from output for QC
        "{params.gatk} BaseRecalibrator -I {output.bam} {params.genome} {params.known_sites} -O {output.table} &>>{log}"  #  


rule merge_recal_bam:
    '''
    here the chr-split recalibrated bams are merged
    this step is needed if samples are needed for PoN-list
    '''

    input: # here I need a switch if no UMI is involved
        expand("recalib/{{sample}}_{{type}}.{chrom}.bam", chrom=chrom_list)
    output:
        "recalib/{sample}_{type}.bam",
        "recalib/{sample}_{type}.bai"
    threads:
        config['resplit_bam']['threads']
    conda:
        "../env/align-env.yml"
    shell:
        # merge all split bams into one bam using samtools merge (also sorts the merged bam)
        "samtools merge {output[0]} recalib/{wildcards.sample}_{wildcards.type}.*.bam; "
        "picard BuildBamIndex INPUT={output[0]}; "
        "rm -f recalib/{wildcards.sample}_{wildcards.type}.*.bam; "

rule cover_BED:
    input:
        sample = "recalib/{sample}_{type}.bam",
        ref_gen = os.path.join(full_path('genome_path'), 'gen_ref.done')
    output:
        "coverBED/{sample}_{type}.txt"
    log:
        "logs/coverBED/{sample}_{type}.log"
    threads: 2
    params:
        format_coverage = get_script('format_bed_coverage'),
        exon_cover = get_bed_file('Covered'),
        prettifyBed = get_script('prettifyBED'),
        fastq = get_fastq_pair,
        refgen = full_path('genome')
    conda:
        "../env/bedcover-env.yml"
    script:
        "../scripts/bedcover.py"
