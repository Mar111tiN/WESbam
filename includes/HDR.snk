rule filter_pileup:
    input:
        bam = "filterbamdone/{sample}_{tumor}-{normal}.filter1.done"
    output:
        pileup = "hdr/{sample}_{tumor}-{normal}.{chrom}.filter1.pileup"
    threads:
        2
    conda:
        f"../{config['envs']}/align-env.yml"
    params:
        # get both the tumor and the normal bam file as input to mpileup
        input = lambda w: f"{config['filter_bam']['folder']}/{w.sample}_{w.tumor}.filter1.bam {config['filter_bam']['folder']}/{w.sample}_{w.normal}.filter1.bam",
        refgen = full_path('genome'),
        qual = f"-q {config['mpileup']['MAPQ']} -Q {config['mpileup']['Q']}",
        cleanpileup = get_script('cleanpileup')
    shell:
        "samtools mpileup -f {params.refgen} -r {wildcards.chrom} {params.qual} {params.input} | {params.cleanpileup} > {output.pileup}"


rule detect_HDR:
    input:
        bam = "filterbam/{sample}_{type}.filter1.bam",
        filter_file = "table/{sample}_{tumor}-{normal}.filter1.csv",
        pileup = "hdr/{sample}_{tumor}-{normal}.{chrom}.filter1.pileup"
    output:
        HDR_table = "hdr/{sample}_{tumor}-{normal}.{chrom}.{type}.filter1.HDR.csv"
    conda:
        f"../{config['envs']}/HDR-env.yml"
    threads:
        config['HDR']['threads']
    params:
        editbamdf =  get_script('editbamdf')
    script:
        "../scripts/HDR.py"



rule mergeHDR:
    input:
        expand("hdr/{{sample}}_{{tumor}}-{{normal}}.{chrom}.{{normal}}.filter1.HDR.csv", chrom=chrom_list),
        expand("hdr/{{sample}}_{{tumor}}-{{normal}}.{chrom}.{{tumor}}.filter1.HDR.csv", chrom=chrom_list)
    output:
        "table/{sample}_{tumor}-{normal}.filter1.HDR.csv"
    threads:
        1
    run:
        tumor_pattern = f"{wildcards.tumor}.filter1"
        normal_pattern = f"{wildcards.normal}.filter1"
        # populate an input dict for better looping
        input_list = {'Tumor': [i for i in input if tumor_pattern in i], 'Normal': [i for i in input if normal_pattern in i]}
        base_cols = ['Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene']
        cols = base_cols.copy()
        dfs = {}
        for T_or_N in ['Tumor', 'Normal']:
            HDR_dfs = []
            for HDR_file in input_list[T_or_N]:
                if os.path.isfile(HDR_file):
                    if os.path.getsize(HDR_file ) > 20:
                        HDR_df = pd.read_csv(HDR_file, sep='\t', index_col=False)
                        # cleanup aftHDR
                        # shell(f"rm {EB_file}")
                        if HDR_df.empty:
                            continue
                        HDR_dfs.append(HDR_df)
            # concat
            HDR_df = pd.concat(HDR_dfs).sort_values(['Chr', 'Start'])
            # change columns
            new_cols = {
                'HDRcand': f'{T_or_N}HDRcand',
                'HDRcount': f'{T_or_N}HDRcount',
                'HDRinfo': f'{T_or_N}HDRinfo'
            }

            HDR_df = HDR_df.rename(columns=new_cols)
            # add new_cols to cols
            cols += new_cols.values()
            # load into dfs dict
            dfs[T_or_N] = HDR_df
        
        HDR_merge = pd.merge(dfs['Tumor'], dfs['Normal'], on=base_cols).sort_values(base_cols[:3])
        # sort columns
        HDR_merge = HDR_merge[cols]

        # ###### PILEUP ANALYSIS ##############################


        HDR_len = len(HDR_merge.query('TumorHDRcount > 0').index)
        HDR_merge.to_csv(output[0], sep='\t', index=False)
        show_output(f"Found {HDR_len} possible HDR mutations. Written HDR file to {output[0]}", color='success')